{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:44:35.816622Z",
     "start_time": "2024-05-20T08:44:31.588423Z"
    }
   },
   "source": "!pip install mediapipe opencv-python pandas scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pandas in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.28)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.28)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\devi prasad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:46:33.657613Z",
     "start_time": "2024-05-20T08:46:16.250865Z"
    }
   },
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "#import pyttsx3"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:46:43.784300Z",
     "start_time": "2024-05-20T08:46:43.780283Z"
    }
   },
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Some Detections"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:15.649607Z",
     "start_time": "2024-05-20T08:46:47.599569Z"
    }
   },
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVI PRASAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:15.694408Z",
     "start_time": "2024-05-20T08:47:15.659906Z"
    }
   },
   "source": [
    "results.face_landmarks.landmark[0].visibility"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Capture Landmarks & Export to CSV\n",
    "<!--<img src=\"https://i.imgur.com/8bForKY.png\">-->\n",
    "<!--<img src=\"https://i.imgur.com/AzKNp7A.png\">-->"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:20.259438Z",
     "start_time": "2024-05-20T08:47:20.249004Z"
    }
   },
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:21.570960Z",
     "start_time": "2024-05-20T08:47:21.561303Z"
    }
   },
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:22.782241Z",
     "start_time": "2024-05-20T08:47:22.759807Z"
    }
   },
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:23.732216Z",
     "start_time": "2024-05-20T08:47:23.709451Z"
    }
   },
   "source": [
    "landmarks"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33',\n",
       " 'x34',\n",
       " 'y34',\n",
       " 'z34',\n",
       " 'v34',\n",
       " 'x35',\n",
       " 'y35',\n",
       " 'z35',\n",
       " 'v35',\n",
       " 'x36',\n",
       " 'y36',\n",
       " 'z36',\n",
       " 'v36',\n",
       " 'x37',\n",
       " 'y37',\n",
       " 'z37',\n",
       " 'v37',\n",
       " 'x38',\n",
       " 'y38',\n",
       " 'z38',\n",
       " 'v38',\n",
       " 'x39',\n",
       " 'y39',\n",
       " 'z39',\n",
       " 'v39',\n",
       " 'x40',\n",
       " 'y40',\n",
       " 'z40',\n",
       " 'v40',\n",
       " 'x41',\n",
       " 'y41',\n",
       " 'z41',\n",
       " 'v41',\n",
       " 'x42',\n",
       " 'y42',\n",
       " 'z42',\n",
       " 'v42',\n",
       " 'x43',\n",
       " 'y43',\n",
       " 'z43',\n",
       " 'v43',\n",
       " 'x44',\n",
       " 'y44',\n",
       " 'z44',\n",
       " 'v44',\n",
       " 'x45',\n",
       " 'y45',\n",
       " 'z45',\n",
       " 'v45',\n",
       " 'x46',\n",
       " 'y46',\n",
       " 'z46',\n",
       " 'v46',\n",
       " 'x47',\n",
       " 'y47',\n",
       " 'z47',\n",
       " 'v47',\n",
       " 'x48',\n",
       " 'y48',\n",
       " 'z48',\n",
       " 'v48',\n",
       " 'x49',\n",
       " 'y49',\n",
       " 'z49',\n",
       " 'v49',\n",
       " 'x50',\n",
       " 'y50',\n",
       " 'z50',\n",
       " 'v50',\n",
       " 'x51',\n",
       " 'y51',\n",
       " 'z51',\n",
       " 'v51',\n",
       " 'x52',\n",
       " 'y52',\n",
       " 'z52',\n",
       " 'v52',\n",
       " 'x53',\n",
       " 'y53',\n",
       " 'z53',\n",
       " 'v53',\n",
       " 'x54',\n",
       " 'y54',\n",
       " 'z54',\n",
       " 'v54',\n",
       " 'x55',\n",
       " 'y55',\n",
       " 'z55',\n",
       " 'v55',\n",
       " 'x56',\n",
       " 'y56',\n",
       " 'z56',\n",
       " 'v56',\n",
       " 'x57',\n",
       " 'y57',\n",
       " 'z57',\n",
       " 'v57',\n",
       " 'x58',\n",
       " 'y58',\n",
       " 'z58',\n",
       " 'v58',\n",
       " 'x59',\n",
       " 'y59',\n",
       " 'z59',\n",
       " 'v59',\n",
       " 'x60',\n",
       " 'y60',\n",
       " 'z60',\n",
       " 'v60',\n",
       " 'x61',\n",
       " 'y61',\n",
       " 'z61',\n",
       " 'v61',\n",
       " 'x62',\n",
       " 'y62',\n",
       " 'z62',\n",
       " 'v62',\n",
       " 'x63',\n",
       " 'y63',\n",
       " 'z63',\n",
       " 'v63',\n",
       " 'x64',\n",
       " 'y64',\n",
       " 'z64',\n",
       " 'v64',\n",
       " 'x65',\n",
       " 'y65',\n",
       " 'z65',\n",
       " 'v65',\n",
       " 'x66',\n",
       " 'y66',\n",
       " 'z66',\n",
       " 'v66',\n",
       " 'x67',\n",
       " 'y67',\n",
       " 'z67',\n",
       " 'v67',\n",
       " 'x68',\n",
       " 'y68',\n",
       " 'z68',\n",
       " 'v68',\n",
       " 'x69',\n",
       " 'y69',\n",
       " 'z69',\n",
       " 'v69',\n",
       " 'x70',\n",
       " 'y70',\n",
       " 'z70',\n",
       " 'v70',\n",
       " 'x71',\n",
       " 'y71',\n",
       " 'z71',\n",
       " 'v71',\n",
       " 'x72',\n",
       " 'y72',\n",
       " 'z72',\n",
       " 'v72',\n",
       " 'x73',\n",
       " 'y73',\n",
       " 'z73',\n",
       " 'v73',\n",
       " 'x74',\n",
       " 'y74',\n",
       " 'z74',\n",
       " 'v74',\n",
       " 'x75',\n",
       " 'y75',\n",
       " 'z75',\n",
       " 'v75',\n",
       " 'x76',\n",
       " 'y76',\n",
       " 'z76',\n",
       " 'v76',\n",
       " 'x77',\n",
       " 'y77',\n",
       " 'z77',\n",
       " 'v77',\n",
       " 'x78',\n",
       " 'y78',\n",
       " 'z78',\n",
       " 'v78',\n",
       " 'x79',\n",
       " 'y79',\n",
       " 'z79',\n",
       " 'v79',\n",
       " 'x80',\n",
       " 'y80',\n",
       " 'z80',\n",
       " 'v80',\n",
       " 'x81',\n",
       " 'y81',\n",
       " 'z81',\n",
       " 'v81',\n",
       " 'x82',\n",
       " 'y82',\n",
       " 'z82',\n",
       " 'v82',\n",
       " 'x83',\n",
       " 'y83',\n",
       " 'z83',\n",
       " 'v83',\n",
       " 'x84',\n",
       " 'y84',\n",
       " 'z84',\n",
       " 'v84',\n",
       " 'x85',\n",
       " 'y85',\n",
       " 'z85',\n",
       " 'v85',\n",
       " 'x86',\n",
       " 'y86',\n",
       " 'z86',\n",
       " 'v86',\n",
       " 'x87',\n",
       " 'y87',\n",
       " 'z87',\n",
       " 'v87',\n",
       " 'x88',\n",
       " 'y88',\n",
       " 'z88',\n",
       " 'v88',\n",
       " 'x89',\n",
       " 'y89',\n",
       " 'z89',\n",
       " 'v89',\n",
       " 'x90',\n",
       " 'y90',\n",
       " 'z90',\n",
       " 'v90',\n",
       " 'x91',\n",
       " 'y91',\n",
       " 'z91',\n",
       " 'v91',\n",
       " 'x92',\n",
       " 'y92',\n",
       " 'z92',\n",
       " 'v92',\n",
       " 'x93',\n",
       " 'y93',\n",
       " 'z93',\n",
       " 'v93',\n",
       " 'x94',\n",
       " 'y94',\n",
       " 'z94',\n",
       " 'v94',\n",
       " 'x95',\n",
       " 'y95',\n",
       " 'z95',\n",
       " 'v95',\n",
       " 'x96',\n",
       " 'y96',\n",
       " 'z96',\n",
       " 'v96',\n",
       " 'x97',\n",
       " 'y97',\n",
       " 'z97',\n",
       " 'v97',\n",
       " 'x98',\n",
       " 'y98',\n",
       " 'z98',\n",
       " 'v98',\n",
       " 'x99',\n",
       " 'y99',\n",
       " 'z99',\n",
       " 'v99',\n",
       " 'x100',\n",
       " 'y100',\n",
       " 'z100',\n",
       " 'v100',\n",
       " 'x101',\n",
       " 'y101',\n",
       " 'z101',\n",
       " 'v101',\n",
       " 'x102',\n",
       " 'y102',\n",
       " 'z102',\n",
       " 'v102',\n",
       " 'x103',\n",
       " 'y103',\n",
       " 'z103',\n",
       " 'v103',\n",
       " 'x104',\n",
       " 'y104',\n",
       " 'z104',\n",
       " 'v104',\n",
       " 'x105',\n",
       " 'y105',\n",
       " 'z105',\n",
       " 'v105',\n",
       " 'x106',\n",
       " 'y106',\n",
       " 'z106',\n",
       " 'v106',\n",
       " 'x107',\n",
       " 'y107',\n",
       " 'z107',\n",
       " 'v107',\n",
       " 'x108',\n",
       " 'y108',\n",
       " 'z108',\n",
       " 'v108',\n",
       " 'x109',\n",
       " 'y109',\n",
       " 'z109',\n",
       " 'v109',\n",
       " 'x110',\n",
       " 'y110',\n",
       " 'z110',\n",
       " 'v110',\n",
       " 'x111',\n",
       " 'y111',\n",
       " 'z111',\n",
       " 'v111',\n",
       " 'x112',\n",
       " 'y112',\n",
       " 'z112',\n",
       " 'v112',\n",
       " 'x113',\n",
       " 'y113',\n",
       " 'z113',\n",
       " 'v113',\n",
       " 'x114',\n",
       " 'y114',\n",
       " 'z114',\n",
       " 'v114',\n",
       " 'x115',\n",
       " 'y115',\n",
       " 'z115',\n",
       " 'v115',\n",
       " 'x116',\n",
       " 'y116',\n",
       " 'z116',\n",
       " 'v116',\n",
       " 'x117',\n",
       " 'y117',\n",
       " 'z117',\n",
       " 'v117',\n",
       " 'x118',\n",
       " 'y118',\n",
       " 'z118',\n",
       " 'v118',\n",
       " 'x119',\n",
       " 'y119',\n",
       " 'z119',\n",
       " 'v119',\n",
       " 'x120',\n",
       " 'y120',\n",
       " 'z120',\n",
       " 'v120',\n",
       " 'x121',\n",
       " 'y121',\n",
       " 'z121',\n",
       " 'v121',\n",
       " 'x122',\n",
       " 'y122',\n",
       " 'z122',\n",
       " 'v122',\n",
       " 'x123',\n",
       " 'y123',\n",
       " 'z123',\n",
       " 'v123',\n",
       " 'x124',\n",
       " 'y124',\n",
       " 'z124',\n",
       " 'v124',\n",
       " 'x125',\n",
       " 'y125',\n",
       " 'z125',\n",
       " 'v125',\n",
       " 'x126',\n",
       " 'y126',\n",
       " 'z126',\n",
       " 'v126',\n",
       " 'x127',\n",
       " 'y127',\n",
       " 'z127',\n",
       " 'v127',\n",
       " 'x128',\n",
       " 'y128',\n",
       " 'z128',\n",
       " 'v128',\n",
       " 'x129',\n",
       " 'y129',\n",
       " 'z129',\n",
       " 'v129',\n",
       " 'x130',\n",
       " 'y130',\n",
       " 'z130',\n",
       " 'v130',\n",
       " 'x131',\n",
       " 'y131',\n",
       " 'z131',\n",
       " 'v131',\n",
       " 'x132',\n",
       " 'y132',\n",
       " 'z132',\n",
       " 'v132',\n",
       " 'x133',\n",
       " 'y133',\n",
       " 'z133',\n",
       " 'v133',\n",
       " 'x134',\n",
       " 'y134',\n",
       " 'z134',\n",
       " 'v134',\n",
       " 'x135',\n",
       " 'y135',\n",
       " 'z135',\n",
       " 'v135',\n",
       " 'x136',\n",
       " 'y136',\n",
       " 'z136',\n",
       " 'v136',\n",
       " 'x137',\n",
       " 'y137',\n",
       " 'z137',\n",
       " 'v137',\n",
       " 'x138',\n",
       " 'y138',\n",
       " 'z138',\n",
       " 'v138',\n",
       " 'x139',\n",
       " 'y139',\n",
       " 'z139',\n",
       " 'v139',\n",
       " 'x140',\n",
       " 'y140',\n",
       " 'z140',\n",
       " 'v140',\n",
       " 'x141',\n",
       " 'y141',\n",
       " 'z141',\n",
       " 'v141',\n",
       " 'x142',\n",
       " 'y142',\n",
       " 'z142',\n",
       " 'v142',\n",
       " 'x143',\n",
       " 'y143',\n",
       " 'z143',\n",
       " 'v143',\n",
       " 'x144',\n",
       " 'y144',\n",
       " 'z144',\n",
       " 'v144',\n",
       " 'x145',\n",
       " 'y145',\n",
       " 'z145',\n",
       " 'v145',\n",
       " 'x146',\n",
       " 'y146',\n",
       " 'z146',\n",
       " 'v146',\n",
       " 'x147',\n",
       " 'y147',\n",
       " 'z147',\n",
       " 'v147',\n",
       " 'x148',\n",
       " 'y148',\n",
       " 'z148',\n",
       " 'v148',\n",
       " 'x149',\n",
       " 'y149',\n",
       " 'z149',\n",
       " 'v149',\n",
       " 'x150',\n",
       " 'y150',\n",
       " 'z150',\n",
       " 'v150',\n",
       " 'x151',\n",
       " 'y151',\n",
       " 'z151',\n",
       " 'v151',\n",
       " 'x152',\n",
       " 'y152',\n",
       " 'z152',\n",
       " 'v152',\n",
       " 'x153',\n",
       " 'y153',\n",
       " 'z153',\n",
       " 'v153',\n",
       " 'x154',\n",
       " 'y154',\n",
       " 'z154',\n",
       " 'v154',\n",
       " 'x155',\n",
       " 'y155',\n",
       " 'z155',\n",
       " 'v155',\n",
       " 'x156',\n",
       " 'y156',\n",
       " 'z156',\n",
       " 'v156',\n",
       " 'x157',\n",
       " 'y157',\n",
       " 'z157',\n",
       " 'v157',\n",
       " 'x158',\n",
       " 'y158',\n",
       " 'z158',\n",
       " 'v158',\n",
       " 'x159',\n",
       " 'y159',\n",
       " 'z159',\n",
       " 'v159',\n",
       " 'x160',\n",
       " 'y160',\n",
       " 'z160',\n",
       " 'v160',\n",
       " 'x161',\n",
       " 'y161',\n",
       " 'z161',\n",
       " 'v161',\n",
       " 'x162',\n",
       " 'y162',\n",
       " 'z162',\n",
       " 'v162',\n",
       " 'x163',\n",
       " 'y163',\n",
       " 'z163',\n",
       " 'v163',\n",
       " 'x164',\n",
       " 'y164',\n",
       " 'z164',\n",
       " 'v164',\n",
       " 'x165',\n",
       " 'y165',\n",
       " 'z165',\n",
       " 'v165',\n",
       " 'x166',\n",
       " 'y166',\n",
       " 'z166',\n",
       " 'v166',\n",
       " 'x167',\n",
       " 'y167',\n",
       " 'z167',\n",
       " 'v167',\n",
       " 'x168',\n",
       " 'y168',\n",
       " 'z168',\n",
       " 'v168',\n",
       " 'x169',\n",
       " 'y169',\n",
       " 'z169',\n",
       " 'v169',\n",
       " 'x170',\n",
       " 'y170',\n",
       " 'z170',\n",
       " 'v170',\n",
       " 'x171',\n",
       " 'y171',\n",
       " 'z171',\n",
       " 'v171',\n",
       " 'x172',\n",
       " 'y172',\n",
       " 'z172',\n",
       " 'v172',\n",
       " 'x173',\n",
       " 'y173',\n",
       " 'z173',\n",
       " 'v173',\n",
       " 'x174',\n",
       " 'y174',\n",
       " 'z174',\n",
       " 'v174',\n",
       " 'x175',\n",
       " 'y175',\n",
       " 'z175',\n",
       " 'v175',\n",
       " 'x176',\n",
       " 'y176',\n",
       " 'z176',\n",
       " 'v176',\n",
       " 'x177',\n",
       " 'y177',\n",
       " 'z177',\n",
       " 'v177',\n",
       " 'x178',\n",
       " 'y178',\n",
       " 'z178',\n",
       " 'v178',\n",
       " 'x179',\n",
       " 'y179',\n",
       " 'z179',\n",
       " 'v179',\n",
       " 'x180',\n",
       " 'y180',\n",
       " 'z180',\n",
       " 'v180',\n",
       " 'x181',\n",
       " 'y181',\n",
       " 'z181',\n",
       " 'v181',\n",
       " 'x182',\n",
       " 'y182',\n",
       " 'z182',\n",
       " 'v182',\n",
       " 'x183',\n",
       " 'y183',\n",
       " 'z183',\n",
       " 'v183',\n",
       " 'x184',\n",
       " 'y184',\n",
       " 'z184',\n",
       " 'v184',\n",
       " 'x185',\n",
       " 'y185',\n",
       " 'z185',\n",
       " 'v185',\n",
       " 'x186',\n",
       " 'y186',\n",
       " 'z186',\n",
       " 'v186',\n",
       " 'x187',\n",
       " 'y187',\n",
       " 'z187',\n",
       " 'v187',\n",
       " 'x188',\n",
       " 'y188',\n",
       " 'z188',\n",
       " 'v188',\n",
       " 'x189',\n",
       " 'y189',\n",
       " 'z189',\n",
       " 'v189',\n",
       " 'x190',\n",
       " 'y190',\n",
       " 'z190',\n",
       " 'v190',\n",
       " 'x191',\n",
       " 'y191',\n",
       " 'z191',\n",
       " 'v191',\n",
       " 'x192',\n",
       " 'y192',\n",
       " 'z192',\n",
       " 'v192',\n",
       " 'x193',\n",
       " 'y193',\n",
       " 'z193',\n",
       " 'v193',\n",
       " 'x194',\n",
       " 'y194',\n",
       " 'z194',\n",
       " 'v194',\n",
       " 'x195',\n",
       " 'y195',\n",
       " 'z195',\n",
       " 'v195',\n",
       " 'x196',\n",
       " 'y196',\n",
       " 'z196',\n",
       " 'v196',\n",
       " 'x197',\n",
       " 'y197',\n",
       " 'z197',\n",
       " 'v197',\n",
       " 'x198',\n",
       " 'y198',\n",
       " 'z198',\n",
       " 'v198',\n",
       " 'x199',\n",
       " 'y199',\n",
       " 'z199',\n",
       " 'v199',\n",
       " 'x200',\n",
       " 'y200',\n",
       " 'z200',\n",
       " 'v200',\n",
       " 'x201',\n",
       " 'y201',\n",
       " 'z201',\n",
       " 'v201',\n",
       " 'x202',\n",
       " 'y202',\n",
       " 'z202',\n",
       " 'v202',\n",
       " 'x203',\n",
       " 'y203',\n",
       " 'z203',\n",
       " 'v203',\n",
       " 'x204',\n",
       " 'y204',\n",
       " 'z204',\n",
       " 'v204',\n",
       " 'x205',\n",
       " 'y205',\n",
       " 'z205',\n",
       " 'v205',\n",
       " 'x206',\n",
       " 'y206',\n",
       " 'z206',\n",
       " 'v206',\n",
       " 'x207',\n",
       " 'y207',\n",
       " 'z207',\n",
       " 'v207',\n",
       " 'x208',\n",
       " 'y208',\n",
       " 'z208',\n",
       " 'v208',\n",
       " 'x209',\n",
       " 'y209',\n",
       " 'z209',\n",
       " 'v209',\n",
       " 'x210',\n",
       " 'y210',\n",
       " 'z210',\n",
       " 'v210',\n",
       " 'x211',\n",
       " 'y211',\n",
       " 'z211',\n",
       " 'v211',\n",
       " 'x212',\n",
       " 'y212',\n",
       " 'z212',\n",
       " 'v212',\n",
       " 'x213',\n",
       " 'y213',\n",
       " 'z213',\n",
       " 'v213',\n",
       " 'x214',\n",
       " 'y214',\n",
       " 'z214',\n",
       " 'v214',\n",
       " 'x215',\n",
       " 'y215',\n",
       " 'z215',\n",
       " 'v215',\n",
       " 'x216',\n",
       " 'y216',\n",
       " 'z216',\n",
       " 'v216',\n",
       " 'x217',\n",
       " 'y217',\n",
       " 'z217',\n",
       " 'v217',\n",
       " 'x218',\n",
       " 'y218',\n",
       " 'z218',\n",
       " 'v218',\n",
       " 'x219',\n",
       " 'y219',\n",
       " 'z219',\n",
       " 'v219',\n",
       " 'x220',\n",
       " 'y220',\n",
       " 'z220',\n",
       " 'v220',\n",
       " 'x221',\n",
       " 'y221',\n",
       " 'z221',\n",
       " 'v221',\n",
       " 'x222',\n",
       " 'y222',\n",
       " 'z222',\n",
       " 'v222',\n",
       " 'x223',\n",
       " 'y223',\n",
       " 'z223',\n",
       " 'v223',\n",
       " 'x224',\n",
       " 'y224',\n",
       " 'z224',\n",
       " 'v224',\n",
       " 'x225',\n",
       " 'y225',\n",
       " 'z225',\n",
       " 'v225',\n",
       " 'x226',\n",
       " 'y226',\n",
       " 'z226',\n",
       " 'v226',\n",
       " 'x227',\n",
       " 'y227',\n",
       " 'z227',\n",
       " 'v227',\n",
       " 'x228',\n",
       " 'y228',\n",
       " 'z228',\n",
       " 'v228',\n",
       " 'x229',\n",
       " 'y229',\n",
       " 'z229',\n",
       " 'v229',\n",
       " 'x230',\n",
       " 'y230',\n",
       " 'z230',\n",
       " 'v230',\n",
       " 'x231',\n",
       " 'y231',\n",
       " 'z231',\n",
       " 'v231',\n",
       " 'x232',\n",
       " 'y232',\n",
       " 'z232',\n",
       " 'v232',\n",
       " 'x233',\n",
       " 'y233',\n",
       " 'z233',\n",
       " 'v233',\n",
       " 'x234',\n",
       " 'y234',\n",
       " 'z234',\n",
       " 'v234',\n",
       " 'x235',\n",
       " 'y235',\n",
       " 'z235',\n",
       " 'v235',\n",
       " 'x236',\n",
       " 'y236',\n",
       " 'z236',\n",
       " 'v236',\n",
       " 'x237',\n",
       " 'y237',\n",
       " 'z237',\n",
       " 'v237',\n",
       " 'x238',\n",
       " 'y238',\n",
       " 'z238',\n",
       " 'v238',\n",
       " 'x239',\n",
       " 'y239',\n",
       " 'z239',\n",
       " 'v239',\n",
       " 'x240',\n",
       " 'y240',\n",
       " 'z240',\n",
       " 'v240',\n",
       " 'x241',\n",
       " 'y241',\n",
       " 'z241',\n",
       " 'v241',\n",
       " 'x242',\n",
       " 'y242',\n",
       " 'z242',\n",
       " 'v242',\n",
       " 'x243',\n",
       " 'y243',\n",
       " 'z243',\n",
       " 'v243',\n",
       " 'x244',\n",
       " 'y244',\n",
       " 'z244',\n",
       " 'v244',\n",
       " 'x245',\n",
       " 'y245',\n",
       " 'z245',\n",
       " 'v245',\n",
       " 'x246',\n",
       " 'y246',\n",
       " 'z246',\n",
       " 'v246',\n",
       " 'x247',\n",
       " 'y247',\n",
       " 'z247',\n",
       " 'v247',\n",
       " 'x248',\n",
       " 'y248',\n",
       " 'z248',\n",
       " 'v248',\n",
       " 'x249',\n",
       " 'y249',\n",
       " 'z249',\n",
       " 'v249',\n",
       " 'x250',\n",
       " 'y250',\n",
       " 'z250',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:24.519022Z",
     "start_time": "2024-05-20T08:47:24.498155Z"
    }
   },
   "source": [
    "with open('coords_body.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:29:27.699275Z",
     "start_time": "2024-05-11T12:29:27.680182Z"
    }
   },
   "source": "class_name = \"up\"",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:29:53.670470Z",
     "start_time": "2024-05-11T12:29:28.326068Z"
    }
   },
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVI PRASAD\\PycharmProjects\\mp1\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:01:49.940658Z",
     "start_time": "2024-05-11T13:01:49.408937Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:47:43.155160Z",
     "start_time": "2024-05-20T08:47:39.267790Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:49:26.302245Z",
     "start_time": "2024-05-20T09:49:23.789896Z"
    }
   },
   "source": "df = pd.read_csv('cccc - Copy.csv')",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:49:27.524267Z",
     "start_time": "2024-05-20T09:49:27.444789Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  Happy  0.478581  0.142641 -0.396382  0.999986  0.485525  0.127812   \n",
       "1  Happy  0.479360  0.140137 -0.400340  0.999987  0.486805  0.125486   \n",
       "2  Happy  0.479205  0.136620 -0.400550  0.999987  0.486788  0.122603   \n",
       "3  Happy  0.480879  0.135140 -0.401054  0.999988  0.488752  0.121045   \n",
       "4  Happy  0.482973  0.128265 -0.405486  0.999988  0.491288  0.114214   \n",
       "\n",
       "         z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0 -0.375878  0.999945  0.490169  ...  0.001414     0  0.496758  0.123328   \n",
       "1 -0.381666  0.999948  0.491640  ...  0.000864     0  0.499715  0.118803   \n",
       "2 -0.382463  0.999951  0.491624  ...  0.000380     0  0.499134  0.116508   \n",
       "3 -0.382619  0.999954  0.493549  ...  0.000521     0  0.501757  0.115504   \n",
       "4 -0.387945  0.999955  0.496005  ...  0.000076     0  0.505650  0.108146   \n",
       "\n",
       "       z500  v500      x501      y501      z501  v501  \n",
       "0  0.005035     0  0.498209  0.121215  0.005167     0  \n",
       "1  0.003281     0  0.501256  0.116677  0.003296     0  \n",
       "2  0.002796     0  0.500499  0.114602  0.002805     0  \n",
       "3  0.002952     0  0.503297  0.113515  0.002943     0  \n",
       "4  0.002366     0  0.507071  0.106339  0.002307     0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.478581</td>\n",
       "      <td>0.142641</td>\n",
       "      <td>-0.396382</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.485525</td>\n",
       "      <td>0.127812</td>\n",
       "      <td>-0.375878</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.490169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496758</td>\n",
       "      <td>0.123328</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498209</td>\n",
       "      <td>0.121215</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.479360</td>\n",
       "      <td>0.140137</td>\n",
       "      <td>-0.400340</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.486805</td>\n",
       "      <td>0.125486</td>\n",
       "      <td>-0.381666</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499715</td>\n",
       "      <td>0.118803</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501256</td>\n",
       "      <td>0.116677</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.479205</td>\n",
       "      <td>0.136620</td>\n",
       "      <td>-0.400550</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.486788</td>\n",
       "      <td>0.122603</td>\n",
       "      <td>-0.382463</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.491624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499134</td>\n",
       "      <td>0.116508</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500499</td>\n",
       "      <td>0.114602</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.480879</td>\n",
       "      <td>0.135140</td>\n",
       "      <td>-0.401054</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.488752</td>\n",
       "      <td>0.121045</td>\n",
       "      <td>-0.382619</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.493549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501757</td>\n",
       "      <td>0.115504</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503297</td>\n",
       "      <td>0.113515</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.482973</td>\n",
       "      <td>0.128265</td>\n",
       "      <td>-0.405486</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.491288</td>\n",
       "      <td>0.114214</td>\n",
       "      <td>-0.387945</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.496005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505650</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507071</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:49:48.089221Z",
     "start_time": "2024-05-20T09:49:48.042210Z"
    }
   },
   "source": "df.tail()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     class        x1        y1        z1        v1        x2        y2  \\\n",
       "2406  Slap  0.411136  0.105137 -0.400048  0.999859  0.417964  0.088780   \n",
       "2407  Slap  0.403427  0.101703 -0.365814  0.999871  0.408840  0.086042   \n",
       "2408  Slap  0.399416  0.095555 -0.404744  0.999880  0.404372  0.079124   \n",
       "2409  Slap  0.394265  0.093094 -0.446516  0.999889  0.399659  0.075636   \n",
       "2410  Slap  0.399794  0.097867 -0.423419  0.999898  0.405933  0.080992   \n",
       "\n",
       "            z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "2406 -0.370520  0.999763  0.422305  ...  0.002116     0  0.423985  0.087421   \n",
       "2407 -0.334183  0.999785  0.413005  ...  0.002672     0  0.415873  0.086666   \n",
       "2408 -0.378877  0.999799  0.408697  ...  0.002923     0  0.413110  0.079288   \n",
       "2409 -0.423498  0.999814  0.404020  ...  0.002229     0  0.414042  0.078478   \n",
       "2410 -0.396921  0.999828  0.407322  ...  0.001654     0  0.435584  0.090012   \n",
       "\n",
       "          z500  v500      x501      y501      z501  v501  \n",
       "2406  0.011668     0  0.425382  0.086368  0.012194     0  \n",
       "2407  0.012526     0  0.417058  0.085581  0.013078     0  \n",
       "2408  0.011950     0  0.414382  0.077991  0.012505     0  \n",
       "2409  0.012520     0  0.415412  0.077330  0.013072     0  \n",
       "2410  0.009966     0  0.437245  0.088636  0.010431     0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>Slap</td>\n",
       "      <td>0.411136</td>\n",
       "      <td>0.105137</td>\n",
       "      <td>-0.400048</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.417964</td>\n",
       "      <td>0.088780</td>\n",
       "      <td>-0.370520</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.422305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423985</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.425382</td>\n",
       "      <td>0.086368</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>Slap</td>\n",
       "      <td>0.403427</td>\n",
       "      <td>0.101703</td>\n",
       "      <td>-0.365814</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.408840</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>-0.334183</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.413005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.086666</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417058</td>\n",
       "      <td>0.085581</td>\n",
       "      <td>0.013078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>Slap</td>\n",
       "      <td>0.399416</td>\n",
       "      <td>0.095555</td>\n",
       "      <td>-0.404744</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.404372</td>\n",
       "      <td>0.079124</td>\n",
       "      <td>-0.378877</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.408697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413110</td>\n",
       "      <td>0.079288</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414382</td>\n",
       "      <td>0.077991</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>Slap</td>\n",
       "      <td>0.394265</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>-0.446516</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.399659</td>\n",
       "      <td>0.075636</td>\n",
       "      <td>-0.423498</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.404020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414042</td>\n",
       "      <td>0.078478</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415412</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>Slap</td>\n",
       "      <td>0.399794</td>\n",
       "      <td>0.097867</td>\n",
       "      <td>-0.423419</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.405933</td>\n",
       "      <td>0.080992</td>\n",
       "      <td>-0.396921</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.407322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435584</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437245</td>\n",
       "      <td>0.088636</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:48:06.400737Z",
     "start_time": "2024-05-20T08:48:06.388069Z"
    }
   },
   "source": "df[df['class']=='go left']",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, x1, y1, z1, v1, x2, y2, z2, v2, x3, y3, z3, v3, x4, y4, z4, v4, x5, y5, z5, v5, x6, y6, z6, v6, x7, y7, z7, v7, x8, y8, z8, v8, x9, y9, z9, v9, x10, y10, z10, v10, x11, y11, z11, v11, x12, y12, z12, v12, x13, y13, z13, v13, x14, y14, z14, v14, x15, y15, z15, v15, x16, y16, z16, v16, x17, y17, z17, v17, x18, y18, z18, v18, x19, y19, z19, v19, x20, y20, z20, v20, x21, y21, z21, v21, x22, y22, z22, v22, x23, y23, z23, v23, x24, y24, z24, v24, x25, y25, z25, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2005 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2005 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:50:17.004127Z",
     "start_time": "2024-05-20T09:50:16.960448Z"
    }
   },
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:50:19.896640Z",
     "start_time": "2024-05-20T09:50:19.811361Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:50:21.012842Z",
     "start_time": "2024-05-20T09:50:21.001910Z"
    }
   },
   "source": [
    "y_test"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451        Left\n",
       "2360        Slap\n",
       "62         Happy\n",
       "1468        Left\n",
       "979           Hi\n",
       "          ...   \n",
       "1236    Hands Up\n",
       "271        Happy\n",
       "2277        Slap\n",
       "884      Namaste\n",
       "875      Namaste\n",
       "Name: class, Length: 724, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:50:23.405259Z",
     "start_time": "2024-05-20T09:50:23.394546Z"
    }
   },
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:50:24.399359Z",
     "start_time": "2024-05-20T09:50:24.386387Z"
    }
   },
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T10:00:33.571073Z",
     "start_time": "2024-05-20T09:50:25.560527Z"
    }
   },
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVI PRASAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m fit_models \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m algo, pipeline \u001B[38;5;129;01min\u001B[39;00m pipelines\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m----> 3\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     fit_models[algo] \u001B[38;5;241m=\u001B[39m model\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:475\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    473\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    474\u001B[0m         last_step_params \u001B[38;5;241m=\u001B[39m routed_params[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m--> 475\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_final_estimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mlast_step_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfit\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:784\u001B[0m, in \u001B[0;36mBaseGradientBoosting.fit\u001B[1;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resize_state()\n\u001B[0;32m    783\u001B[0m \u001B[38;5;66;03m# fit the boosting stages\u001B[39;00m\n\u001B[1;32m--> 784\u001B[0m n_stages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stages\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rng\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbegin_at_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001B[39;00m\n\u001B[0;32m    798\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_stages \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:880\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stages\u001B[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001B[0m\n\u001B[0;32m    873\u001B[0m         initial_loss \u001B[38;5;241m=\u001B[39m factor \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss(\n\u001B[0;32m    874\u001B[0m             y_true\u001B[38;5;241m=\u001B[39my_oob_masked,\n\u001B[0;32m    875\u001B[0m             raw_prediction\u001B[38;5;241m=\u001B[39mraw_predictions[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    876\u001B[0m             sample_weight\u001B[38;5;241m=\u001B[39msample_weight_oob_masked,\n\u001B[0;32m    877\u001B[0m         )\n\u001B[0;32m    879\u001B[0m \u001B[38;5;66;03m# fit next stage of trees\u001B[39;00m\n\u001B[1;32m--> 880\u001B[0m raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    886\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    887\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_csc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_csr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;66;03m# track loss\u001B[39;00m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_oob:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stage\u001B[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001B[0m\n\u001B[0;32m    487\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;241m*\u001B[39m sample_mask\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m    489\u001B[0m X \u001B[38;5;241m=\u001B[39m X_csc \u001B[38;5;28;01mif\u001B[39;00m X_csc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m X\n\u001B[1;32m--> 490\u001B[0m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg_g_view\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m    492\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;66;03m# update tree leaves\u001B[39;00m\n\u001B[0;32m    495\u001B[0m X_for_tree_update \u001B[38;5;241m=\u001B[39m X_csr \u001B[38;5;28;01mif\u001B[39;00m X_csr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m X\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001B[0m, in \u001B[0;36mDecisionTreeRegressor.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m   1347\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1349\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001B[39;00m\n\u001B[0;32m   1350\u001B[0m \n\u001B[0;32m   1351\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1374\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1377\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1378\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1379\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1380\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1382\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    462\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[0;32m    463\u001B[0m         splitter,\n\u001B[0;32m    464\u001B[0m         min_samples_split,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    469\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[0;32m    470\u001B[0m     )\n\u001B[1;32m--> 472\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    475\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:48:38.372932Z",
     "start_time": "2024-05-20T08:48:38.353091Z"
    }
   },
   "source": "fit_models",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:48:39.577400Z",
     "start_time": "2024-05-20T08:48:39.545061Z"
    }
   },
   "source": "fit_models['lr'].predict(X_test)",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lr'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfit_models\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'lr'"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:41:14.160809Z",
     "start_time": "2024-05-11T12:41:14.152959Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install tensorflow\n",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:41:15.129879Z",
     "start_time": "2024-05-11T12:41:15.123041Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate and Serialize Model "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:41:17.147450Z",
     "start_time": "2024-05-11T12:41:17.111875Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:41:18.779425Z",
     "start_time": "2024-05-11T12:41:18.296835Z"
    }
   },
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 1.0\n",
      "gb 1.0\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:44:06.686781Z",
     "start_time": "2024-05-11T12:44:06.653567Z"
    }
   },
   "source": "fit_models['lr'].predict(X_test)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hii', 'up', 'go right', 'happy', 'go right', 'hii', 'go left',\n",
       "       'hii', 'up', 'go right', 'up', 'go right', 'happy', 'up', 'happy',\n",
       "       'up', 'hii', 'go right', 'hii', 'up', 'hii', 'hii', 'go right',\n",
       "       'hii', 'up', 'person', 'go right', 'go left', 'hii', 'up',\n",
       "       'go left', 'hii', 'happy', 'go right', 'hii', 'go right', 'person',\n",
       "       'hii', 'go left', 'go right', 'go left', 'up', 'person', 'person',\n",
       "       'hii', 'go left', 'go right', 'happy', 'happy', 'up', 'person',\n",
       "       'happy', 'up', 'happy', 'go left', 'go right', 'go right',\n",
       "       'go left', 'happy', 'go left', 'up', 'hii', 'person', 'go left',\n",
       "       'go left', 'hii', 'go right', 'up', 'up', 'go right', 'go left',\n",
       "       'hii', 'happy', 'go right', 'go right', 'hii', 'up', 'hii', 'up',\n",
       "       'go right', 'up', 'go left', 'hii', 'go right', 'hii', 'up', 'up',\n",
       "       'go left', 'person', 'up', 'happy', 'hii', 'go right', 'up',\n",
       "       'go left', 'hii', 'go left', 'happy', 'happy', 'person', 'hii',\n",
       "       'happy', 'go right', 'go left', 'hii', 'hii', 'go left',\n",
       "       'go right', 'go left', 'hii', 'go left', 'up', 'go left', 'hii',\n",
       "       'hii', 'hii', 'go right', 'hii', 'hii', 'go right', 'go left',\n",
       "       'happy', 'go left', 'person', 'happy', 'go right', 'person',\n",
       "       'go right', 'hii', 'go left', 'person', 'go right', 'go left',\n",
       "       'go left', 'happy', 'happy', 'go left', 'up', 'happy', 'hii',\n",
       "       'person', 'go right', 'up', 'person', 'up', 'person', 'person',\n",
       "       'happy', 'up', 'happy', 'go right', 'up', 'person', 'go left',\n",
       "       'happy', 'go right', 'person', 'hii', 'person', 'go left', 'up',\n",
       "       'go left', 'go right', 'up', 'person', 'go left', 'happy', 'happy',\n",
       "       'hii', 'go right', 'hii', 'hii', 'hii', 'hii', 'go left', 'up',\n",
       "       'happy', 'happy', 'up', 'go right', 'hii', 'happy', 'hii', 'happy',\n",
       "       'go right', 'up', 'go left', 'go left', 'hii', 'go left', 'person',\n",
       "       'go left', 'go right', 'go right', 'person', 'hii', 'happy',\n",
       "       'happy', 'go left', 'hii', 'happy', 'hii', 'person', 'hii', 'hii',\n",
       "       'go right', 'person', 'person', 'go left', 'go right', 'go right',\n",
       "       'go right', 'up', 'hii', 'happy', 'go right', 'happy', 'go right',\n",
       "       'go right', 'go right', 'happy', 'happy', 'hii', 'happy', 'hii',\n",
       "       'go right', 'person', 'hii', 'go right', 'go right', 'up', 'happy',\n",
       "       'hii', 'go right', 'go left', 'up', 'up', 'go left', 'go right',\n",
       "       'go left', 'person', 'person', 'happy', 'person', 'hii',\n",
       "       'go right', 'happy', 'go right', 'go left', 'go left', 'go left',\n",
       "       'go left', 'go left', 'person', 'go right', 'happy', 'person',\n",
       "       'hii', 'up', 'up', 'hii', 'go right', 'go left', 'up', 'happy',\n",
       "       'person', 'person', 'go right', 'up', 'hii', 'person', 'happy',\n",
       "       'hii', 'go left', 'go right', 'go left', 'happy', 'happy', 'hii',\n",
       "       'hii', 'go left', 'happy', 'hii', 'go left', 'go right',\n",
       "       'go right', 'go right', 'hii', 'happy', 'happy', 'up', 'hii',\n",
       "       'hii', 'hii', 'person', 'go left', 'happy', 'go left', 'go right',\n",
       "       'go right', 'up', 'up', 'hii', 'person', 'go left', 'go left',\n",
       "       'go left', 'happy', 'go right', 'go right', 'happy', 'go right',\n",
       "       'up', 'person', 'up', 'hii', 'go left', 'hii', 'hii', 'hii',\n",
       "       'go left', 'go right', 'person', 'go right', 'hii', 'hii', 'hii',\n",
       "       'up', 'hii', 'go left', 'happy', 'hii', 'happy', 'up', 'hii', 'up',\n",
       "       'hii', 'go right', 'happy', 'go left', 'up', 'hii', 'hii',\n",
       "       'person', 'up', 'up', 'happy', 'person', 'go left', 'hii', 'up',\n",
       "       'go left', 'hii', 'hii', 'happy', 'person', 'go left', 'happy',\n",
       "       'person', 'go left', 'go left', 'hii', 'hii', 'hii', 'up',\n",
       "       'go left', 'go left', 'go left', 'go left', 'person', 'go left',\n",
       "       'go left', 'hii', 'hii', 'go right', 'go right', 'happy', 'hii',\n",
       "       'go right', 'go right', 'up', 'up', 'go right', 'go right',\n",
       "       'person', 'hii', 'happy', 'hii', 'up', 'go right', 'go right',\n",
       "       'up', 'go right', 'hii', 'go right', 'go right', 'up', 'person',\n",
       "       'go right', 'happy', 'go left', 'go right', 'up', 'up', 'person',\n",
       "       'person', 'happy', 'person', 'go left', 'go left', 'go right',\n",
       "       'happy', 'hii', 'go right', 'go right', 'happy', 'up', 'up',\n",
       "       'go left', 'up', 'up', 'go right', 'hii', 'up', 'go right',\n",
       "       'go right', 'hii', 'person', 'go right', 'person', 'happy',\n",
       "       'happy', 'person', 'go right', 'up', 'up', 'happy', 'up', 'person',\n",
       "       'hii', 'hii', 'up', 'go left', 'go left', 'go left', 'up',\n",
       "       'person', 'up', 'person', 'up', 'person', 'happy', 'hii',\n",
       "       'go right', 'go left', 'person', 'go right', 'person', 'go right',\n",
       "       'up', 'up', 'hii', 'hii', 'up', 'happy', 'person', 'up', 'hii',\n",
       "       'person', 'up', 'hii', 'hii', 'happy', 'up', 'go left', 'go right',\n",
       "       'happy', 'hii', 'go left', 'happy', 'happy', 'go left', 'happy',\n",
       "       'go right', 'up', 'person', 'up', 'go left', 'hii', 'go left',\n",
       "       'go left', 'person', 'person', 'happy', 'up', 'happy', 'go right',\n",
       "       'go left', 'go right', 'hii', 'up', 'up', 'person', 'up', 'person',\n",
       "       'up', 'go left', 'happy', 'go right', 'go right', 'person',\n",
       "       'happy', 'happy', 'up', 'go left', 'hii', 'go right', 'hii',\n",
       "       'person', 'go right', 'go right', 'person', 'go left', 'go left',\n",
       "       'go left', 'go right', 'go left', 'hii', 'go right', 'happy',\n",
       "       'hii', 'hii', 'happy', 'go right', 'hii', 'up', 'hii', 'go left',\n",
       "       'up', 'go left', 'go right', 'go right', 'go left', 'happy', 'hii',\n",
       "       'happy', 'hii', 'go right', 'go right', 'hii', 'happy', 'hii',\n",
       "       'person', 'go right', 'person', 'hii', 'go left', 'hii', 'happy',\n",
       "       'person', 'up', 'hii', 'go right', 'up', 'up', 'up', 'go right',\n",
       "       'go left', 'hii', 'go right', 'happy', 'go left', 'go left',\n",
       "       'person', 'up', 'person', 'hii', 'hii', 'hii', 'go right', 'up',\n",
       "       'go left', 'person', 'hii', 'hii', 'happy', 'go left', 'up',\n",
       "       'go right', 'up', 'happy', 'go right', 'person', 'go right',\n",
       "       'go left', 'go right', 'go left', 'hii', 'person', 'person', 'hii',\n",
       "       'go right', 'go right', 'hii', 'go right', 'go left', 'hii',\n",
       "       'go right', 'go right', 'up', 'go right', 'happy', 'go left',\n",
       "       'person', 'go right', 'up', 'up', 'up', 'person', 'go left',\n",
       "       'go right', 'up', 'happy', 'happy', 'hii', 'go left', 'up',\n",
       "       'go right', 'go left', 'up', 'go right', 'go right', 'go right',\n",
       "       'up', 'hii', 'go left', 'person', 'go left', 'person', 'happy',\n",
       "       'go right'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:44:17.052690Z",
     "start_time": "2024-05-11T12:44:17.043084Z"
    }
   },
   "source": [
    "y_test"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614          hii\n",
       "2115          up\n",
       "1418    go right\n",
       "180        happy\n",
       "1654    go right\n",
       "          ...   \n",
       "842       person\n",
       "1153     go left\n",
       "811       person\n",
       "22         happy\n",
       "1521    go right\n",
       "Name: class, Length: 641, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:44:18.142462Z",
     "start_time": "2024-05-11T12:44:18.130922Z"
    }
   },
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:44:19.969261Z",
     "start_time": "2024-05-11T12:44:19.950690Z"
    }
   },
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T12:44:20.757515Z",
     "start_time": "2024-05-11T12:44:20.745475Z"
    }
   },
   "source": [
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ],
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "#engine = pyttsx3.init()\n",
    "#\n",
    "#def text_to_speech(text, rate=100):\n",
    " #   engine.setProperty('rate', rate)  # Adjust speech rate\n",
    "  #  engine.say(text)\n",
    "   # engine.runAndWait()\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#             # Export to CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            #text_to_speech(body_language_class)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:56:27.624589Z",
     "start_time": "2024-05-06T07:56:27.613916Z"
    }
   },
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 189)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T14:39:58.202717Z",
     "start_time": "2024-06-05T14:36:28.974616Z"
    }
   },
   "source": [
    "import time\n",
    "import pyautogui\n",
    "import pyttsx3\n",
    "import cv2\n",
    "import PoseEstimationModule as pem\n",
    "cap=cv2.VideoCapture(0)\n",
    "detector=pem.poseDetector()\n",
    "counter=0\n",
    "st=\"\"\n",
    "stack=[]\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    img=cv2.resize(img,(900,650))\n",
    "    img=cv2.flip(img,1)\n",
    "    hCam, wCam, _ = img.shape\n",
    "    detector.findPose(img,draw=True)\n",
    "    lmList=detector.getPosition(img,draw=True)\n",
    "    if lmList:\n",
    "        p1,p2=lmList[1][1:],lmList[23][1:]\n",
    "        left,right=lmList[18][1:],lmList[19][1:]\n",
    "        shoulder=lmList[12][1:]\n",
    "        l, _, _ = detector.findDistance(p1, p2)\n",
    "        l1, _, _ = detector.findDistance(left, right)\n",
    "        flag=0\n",
    "        st=\"\"\n",
    "        if l1<100:\n",
    "            st=\"Namaste\"\n",
    "        if right[1]<200:\n",
    "            st=\"Hi\"\n",
    "        if right[1]<200 and left[1]<200:\n",
    "            st=\"victory\"\n",
    "        if left[1]<100 and right[1]<100:\n",
    "            st=\"Hands Up\"\n",
    "        if left[0]<150:\n",
    "            st=\"Left\"\n",
    "        if right[0]>750:\n",
    "            st=\"Right\"\n",
    "        if abs(left[0] - right[0]) < 50 and abs(left[1] - right[1]) < 50:\n",
    "            st = \"Clapping\"\n",
    "        head_top = lmList[0][1:]\n",
    "\n",
    "        if abs(right[0] - head_top[0]) < 50 and abs(right[1] - head_top[1]) < 50:\n",
    "            st = \"slap\"\n",
    "        elif abs(left[0] - head_top[0]) < 50 and abs(left[1] - head_top[1]) < 50:\n",
    "            st = \"slap\"\n",
    "\n",
    "        forehead = lmList[0][1:]\n",
    "        if abs(right[0] - forehead[0]) < 50 and abs(right[1] - forehead[1]) < 50:\n",
    "            st = \"Salute\"\n",
    "        \n",
    "        if counter==10:\n",
    "            counter=0\n",
    "        if counter==0 and (not stack or st!=stack[-1]):\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(st)\n",
    "            engine.runAndWait()\n",
    "            stack.append(st)\n",
    "\n",
    "\n",
    "\n",
    "        counter+=1\n",
    "        (w, h), _ = cv2.getTextSize(st, cv2.FONT_HERSHEY_PLAIN, 5, 3)\n",
    "        cv2.rectangle(img, (20, 20), (20 + w, 70 + h), (0, 0, 0),cv2.FILLED)\n",
    "        cv2.putText(img, st, (20, 70), cv2.FONT_HERSHEY_PLAIN, 5, (255, 0, 255), 3)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"New Project\",img)\n",
    "    cv2.waitKey(1)\n",
    "    \n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVI PRASAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m success,img\u001B[38;5;241m=\u001B[39mcap\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m     13\u001B[0m img\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mresize(img,(\u001B[38;5;241m900\u001B[39m,\u001B[38;5;241m650\u001B[39m))\n\u001B[1;32m---> 14\u001B[0m img\u001B[38;5;241m=\u001B[39m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m hCam, wCam, _ \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m     16\u001B[0m detector\u001B[38;5;241m.\u001B[39mfindPose(img,draw\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T10:16:46.941517Z",
     "start_time": "2024-05-20T10:10:32.524823Z"
    }
   },
   "source": [
    "import time\n",
    "import pyautogui\n",
    "import pyttsx3\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import PoseEstimationModule as pem\n",
    "\n",
    "# Initialize video capture and pose detector\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = pem.poseDetector()\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "\n",
    "# Initialize counter and stack for gesture recognition\n",
    "counter = 0\n",
    "st = \"\"\n",
    "stack = []\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img, (900, 650))\n",
    "    img = cv2.flip(img, 1)\n",
    "    hCam, wCam, _ = img.shape\n",
    "    \n",
    "    # Detect pose and get landmark positions\n",
    "    detector.findPose(img, draw=True)\n",
    "    lmList = detector.getPosition(img, draw=True)\n",
    "    \n",
    "    if lmList:\n",
    "        p1, p2 = lmList[1][1:], lmList[23][1:]\n",
    "        left, right = lmList[18][1:], lmList[19][1:]\n",
    "        shoulder = lmList[12][1:]\n",
    "        \n",
    "        # Calculate distances for gesture recognition\n",
    "        l, _, _ = detector.findDistance(p1, p2)\n",
    "        l1, _, _ = detector.findDistance(left, right)\n",
    "        flag = 0\n",
    "        st = \"\"\n",
    "        \n",
    "        # Determine the gesture\n",
    "        if l1 < 100:\n",
    "            st = \"Namaste\"\n",
    "        if right[1] < 200:\n",
    "            st = \"Hi\"\n",
    "        if right[1] < 200 and left[1] < 200:\n",
    "            st = \"Victory\"\n",
    "        if left[1] < 100 and right[1] < 100:\n",
    "            st = \"Hands Up\"\n",
    "        if left[0] < 150:\n",
    "            st = \"Left\"\n",
    "        if right[0] > 750:\n",
    "            st = \"Right\"\n",
    "        if abs(left[0] - right[0]) < 50 and abs(left[1] - right[1]) < 50:\n",
    "            st = \"Clapping\"\n",
    "        head_top = lmList[0][1:]\n",
    "        if abs(right[0] - head_top[0]) < 50 and abs(right[1] - head_top[1]) < 50:\n",
    "            st = \"Slap\"\n",
    "        elif abs(left[0] - head_top[0]) < 50 and abs(left[1] - head_top[1]) < 50:\n",
    "            st = \"Slap\"\n",
    "        forehead = lmList[0][1:]\n",
    "        if abs(right[0] - forehead[0]) < 50 and abs(right[1] - forehead[1]) < 50:\n",
    "            st = \"Salute\"\n",
    "        \n",
    "        # Voice output and stacking unique gestures\n",
    "        if counter == 10:\n",
    "            counter = 0\n",
    "        if counter == 0 and (not stack or st != stack[-1]):\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(st)\n",
    "            engine.runAndWait()\n",
    "            stack.append(st)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        # Put text in a rectangle\n",
    "        (w, h), _ = cv2.getTextSize(st, cv2.FONT_HERSHEY_PLAIN, 5, 3)\n",
    "        cv2.rectangle(img, (20, 20), (20 + w, 70 + h), (0, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(img, st, (20, 70), cv2.FONT_HERSHEY_PLAIN, 5, (255, 0, 255), 3)\n",
    "    \n",
    "    # Detect face mesh\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                img, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1),\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=1)\n",
    "            )\n",
    "            \n",
    "            # Analyze facial gestures\n",
    "            landmarks = face_landmarks.landmark\n",
    "            \n",
    "            # Example landmarks for mouth corners\n",
    "            left_mouth_corner = landmarks[61]\n",
    "            right_mouth_corner = landmarks[291]\n",
    "            top_lip = landmarks[13]\n",
    "            bottom_lip = landmarks[14]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            (w, h), _ = cv2.getTextSize(st, cv2.FONT_HERSHEY_PLAIN, 5, 3)\n",
    "            cv2.rectangle(img, (20, 20), (20 + w, 70 + h), (0, 0, 0), cv2.FILLED)\n",
    "            cv2.putText(img, st, (20, 70), cv2.FONT_HERSHEY_PLAIN, 5, (255, 0, 255), 3)\n",
    "        \n",
    "    # Display the image\n",
    "    cv2.imshow(\"New Project\", img)\n",
    "    cv2.waitKey(1)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVI PRASAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "Exception ignored in: <function BSTR.__del__ at 0x000001B3CF176200>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DEVI PRASAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\comtypes\\__init__.py\", line 683, in __del__\n",
      "    def __del__(self, _free=windll.oleaut32.SysFreeString):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m     success, img \u001B[38;5;241m=\u001B[39m cap\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m---> 23\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m900\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m650\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m     img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mflip(img, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     25\u001B[0m     hCam, wCam, _ \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-06T03:55:30.526113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pyautogui\n",
    "import pyttsx3\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import PoseEstimationModule as pem\n",
    "\n",
    "# Initialize video capture and pose detector\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = pem.poseDetector()\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize counter and stack for gesture recognition\n",
    "counter = 0\n",
    "st = \"\"\n",
    "stack = []\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img, (900, 650))\n",
    "    img = cv2.flip(img, 1)\n",
    "    hCam, wCam, _ = img.shape\n",
    "    \n",
    "    # Detect pose and get landmark positions\n",
    "    detector.findPose(img, draw=True)\n",
    "    lmList = detector.getPosition(img, draw=True)\n",
    "    \n",
    "    if lmList:\n",
    "        p1, p2 = lmList[1][1:], lmList[23][1:]\n",
    "        left, right = lmList[18][1:], lmList[19][1:]\n",
    "        shoulder = lmList[12][1:]\n",
    "        \n",
    "        # Calculate distances for gesture recognition\n",
    "        l, _, _ = detector.findDistance(p1, p2)\n",
    "        l1, _, _ = detector.findDistance(left, right)\n",
    "        flag = 0\n",
    "        st = \"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Voice output and stacking unique gestures\n",
    "        if counter == 10:\n",
    "            counter = 0\n",
    "        if counter == 0 and (not stack or st != stack[-1]):\n",
    "            engine.say(st)\n",
    "            engine.runAndWait()\n",
    "            stack.append(st)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        # Put text in a rectangle\n",
    "        (w, h), _ = cv2.getTextSize(st, cv2.FONT_HERSHEY_PLAIN, 5, 3)\n",
    "        cv2.rectangle(img, (20, 20), (20 + w, 70 + h), (0, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(img, st, (20, 70), cv2.FONT_HERSHEY_PLAIN, 5, (255, 0, 255), 3)\n",
    "    \n",
    "    # Detect face mesh\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                img, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1),\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=1)\n",
    "            )\n",
    "            \n",
    "            # Analyze facial gestures\n",
    "            landmarks = face_landmarks.landmark\n",
    "            \n",
    "            # Example landmarks for mouth corners\n",
    "            left_mouth_corner = landmarks[61]\n",
    "            right_mouth_corner = landmarks[291]\n",
    "            top_lip = landmarks[13]\n",
    "            bottom_lip = landmarks[14]\n",
    "            \n",
    "            # Convert normalized landmarks to pixel coordinates\n",
    "            left_mouth_corner = (int(left_mouth_corner.x * wCam), int(left_mouth_corner.y * hCam))\n",
    "            right_mouth_corner = (int(right_mouth_corner.x * wCam), int(right_mouth_corner.y * hCam))\n",
    "            top_lip = (int(top_lip.x * wCam), int(top_lip.y * hCam))\n",
    "            bottom_lip = (int(bottom_lip.x * wCam), int(bottom_lip.y * hCam))\n",
    "            \n",
    "            # Calculate distances for smile detection\n",
    "            mouth_width = right_mouth_corner[0] - left_mouth_corner[0]\n",
    "            lip_height = bottom_lip[1] - top_lip[1]\n",
    "            \n",
    "            # Detect smile (mouth width is greater than a threshold)\n",
    "            if mouth_width > 60 and lip_height < 20:\n",
    "                st = \"Smile\"\n",
    "            \n",
    "            # Detect sleep gesture (both eyes closed)\n",
    "            left_eye_top = landmarks[159]\n",
    "            left_eye_bottom = landmarks[145]\n",
    "            right_eye_top = landmarks[386]\n",
    "            right_eye_bottom = landmarks[374]\n",
    "            \n",
    "            # Convert normalized landmarks to pixel coordinates\n",
    "            left_eye_top = (int(left_eye_top.x * wCam), int(left_eye_top.y * hCam))\n",
    "            left_eye_bottom = (int(left_eye_bottom.x * wCam), int(left_eye_bottom.y * hCam))\n",
    "            right_eye_top = (int(right_eye_top.x * wCam), int(right_eye_top.y * hCam))\n",
    "            right_eye_bottom = (int(right_eye_bottom.x * wCam), int(right_eye_bottom.y * hCam))\n",
    "            \n",
    "            left_eye_height = left_eye_bottom[1] - left_eye_top[1]\n",
    "            right_eye_height = right_eye_bottom[1] - right_eye_top[1]\n",
    "            \n",
    "            # Detect sleep gesture if both eyes are closed (eye height is less than a threshold)\n",
    "            if left_eye_height < 5 and right_eye_height < 5:\n",
    "                st = \"Sleep\"\n",
    "            \n",
    "            # Voice output for facial gestures\n",
    "            if st in [\"Smile\", \"Sleep\"]:\n",
    "                engine.say(st)\n",
    "                engine.runAndWait()\n",
    "            \n",
    "            # Display text for the detected facial gesture\n",
    "            if st in [\"Smile\", \"Sleep\"]:\n",
    "                (w, h), _ = cv2.getTextSize(st, cv2.FONT_HERSHEY_PLAIN, 5, 3)\n",
    "                cv2.rectangle(img, (20, 20), (20 + w, 70 + h), (0, 0, 0), cv2.FILLED)\n",
    "                cv2.putText(img, st, (20, 70), cv2.FONT_HERSHEY_PLAIN, 5, (255, 0, 255), 3)\n",
    "        \n",
    "    # Display the image\n",
    "    cv2.imshow(\"New Project\", img)\n",
    "    cv2.waitKey(1)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVI PRASAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
